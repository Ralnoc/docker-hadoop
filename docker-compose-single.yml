version: '3'

services:
  namenode:
    platform: linux/amd64
    build:
      context: namenode
      args:
        BASE_IMAGE: hadoop-base:3.1.3
    restart: always
    ports:
      - 9870:9870
      - 9000:9000
    networks:
      - platform_manager
    volumes:
      - namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
    env_file:
      - ./hadoop.env
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9870" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  datanode1:
    platform: linux/amd64
    build:
      context: datanode
      args:
        BASE_IMAGE: hadoop-base:3.1.3
    expose:
      - 9864
    ports:
      - 9164:9864
    depends_on:
      namenode:
        condition: service_healthy
        restart: true
    restart: always
    networks:
      - platform_manager
    env_file:
      - ./hadoop.env
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    healthcheck:
      test: [ "CMD", "nc", "-zv", "localhost", "9864" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  leavesafemode:
    platform: linux/amd64
    image: hadoop-base:3.1.3
    restart: no
    networks:
      - platform_manager
    env_file:
      - ./hadoop.env
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    depends_on:
      namenode:
        condition: service_healthy
        restart: true
      datanode1:
        condition: service_healthy
        restart: true
    command: [ "hdfs", "dfsadmin", "-safemode", "leave"]

  purgecorrupthdfsblocks:
    platform: linux/amd64
    image: hadoop-base:3.1.3
    restart: no
    networks:
      - platform_manager
    env_file:
      - ./hadoop.env
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    depends_on:
      namenode:
        condition: service_healthy
        restart: true
      datanode1:
        condition: service_healthy
        restart: true
      leavesafemode:
        condition: service_completed_successfully
        restart: true
    command: [ "hdfs", "fsck", "/", "-delete"]

  resourcemanager:
    platform: linux/amd64
    build:
      context: resourcemanager
      args:
        BASE_IMAGE: hadoop-base:3.1.3
    restart: no
    networks:
      - platform_manager
    ports:
      - 8088:8088
      - 8030:8030
      - 8031:8031
      - 8032:8032
    depends_on:
      namenode:
        condition: service_healthy
        restart: true
      datanode1:
        condition: service_healthy
        restart: true
      leavesafemode:
        condition: service_completed_successfully
        restart: true
      purgecorrupthdfsblocks:
        condition: service_completed_successfully
        restart: true
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9864"
    env_file:
      - ./hadoop.env
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8088" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  nodemanager1:
    platform: linux/amd64
    build:
      context: nodemanager
      args:
        BASE_IMAGE: hadoop-base:3.1.3
    restart: always
    networks:
      - platform_manager
    depends_on:
      namenode:
        condition: service_healthy
        restart: true
      resourcemanager:
        condition: service_healthy
        restart: true
      datanode1:
        condition: service_healthy
        restart: true
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env

  historyserver:
    platform: linux/amd64
    build:
      context: historyserver
      args:
        BASE_IMAGE: hadoop-base:3.1.3
    ports:
      - 8188:8188
    restart: no
    networks:
      - platform_manager
    depends_on:
      namenode:
        condition: service_healthy
        restart: true
      datanode1:
        condition: service_healthy
        restart: true
      resourcemanager:
        condition: service_healthy
        restart: true
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 datanode1:9864 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8188" ]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

volumes:
  datanode:
  namenode:
  hadoop_historyserver:

networks:
  platform_manager: